# -*- coding: utf-8 -*-
"""NabilaAlawiyah_Submission1_MLT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G0mnPZHx5XQACcCRD07crrrHf3Ksls_X

# Predictive Analytic:  Obesity Levels

- **Nama:** Nabila Alawiyah
- **Email:** nabilaalawiyah.25@gmail.com
- **ID Dicoding:** nabila_alawiyah_B1OF

## Rubrik Tambahan - Domain Proyek

- Menguraikan alasan pentingnya permasalahan dan cara penyelesaiannya. **(SELESAI)**
- Menyertakan hasil riset atau referensi pendukung. **(SELESAI – Referensi jurnal telah disertakan)**

## Rubrik Tambahan - Business Understanding

- Menyediakan dua atau lebih pernyataan solusi, seperti penggunaan lebih dari satu algoritma atau peningkatan model dasar dengan tuning hyperparameter. **(SELESAI – Terdapat 2 pernyataan solusi)**
- Solusi yang diajukan harus dapat diukur dengan metrik evaluasi yang sesuai. **(SELESAI)**

## Rubrik - Data Understanding

- Melakukan tahapan-tahapan penting untuk memahami data, seperti visualisasi data atau analisis eksploratif (EDA).

## Rubrik - Data Preparation

- Menjelaskan tahapan pemrosesan data yang telah dilakukan. **(SELESAI – Telah menggunakan encoding kategorikal, one-hot encoding, train-test split, dan standarisasi)**
- Memberikan penjelasan mengenai alasan pentingnya setiap tahapan data preparation. **(SELESAI – Dibahas pada bagian data preparation)**

## Rubrik - Modeling

- Menjelaskan kelebihan dan kelemahan dari setiap algoritma yang digunakan. **(SELESAI – Dijelaskan pada bagian awal README)**
- Jika hanya menggunakan satu algoritma, maka harus dilakukan peningkatan model melalui hyperparameter tuning. Jelaskan proses tuning-nya. **(SELESAI – Menggunakan Optuna untuk hyperparameter tuning)**
- Jika menggunakan lebih dari satu algoritma, harus dipilih model terbaik dan dijelaskan alasan pemilihannya. **(SELESAI – Pemilihan model dijelaskan melalui visualisasi barplot pada bagian evaluasi dan pemilihan model)**

## Rubrik - Evaluation

- Menjelaskan metrik evaluasi yang digunakan untuk mengukur performa model, termasuk rumus dan mekanisme kerja metrik tersebut. **(SELESAI – Telah dijelaskan di README dan bagian evaluasi model serta pemilihan model)**

# Domain Proyek
Obesitas adalah kondisi medis yang ditandai oleh akumulasi lemak tubuh yang berlebihan, yang dapat meningkatkan risiko berbagai penyakit kronis seperti diabetes tipe 2, penyakit jantung, hipertensi, dan beberapa jenis kanker. Di Indonesia, obesitas telah menjadi masalah kesehatan masyarakat yang signifikan, dengan prevalensi yang terus meningkat dalam beberapa tahun terakhir.

Berdasarkan data Riset Kesehatan Dasar (Riskesdas) 2018, prevalensi obesitas pada penduduk dewasa di Indonesia mencapai 21,8%, meningkat dari 14,8% pada tahun 2013 . Peningkatan ini menunjukkan tren yang mengkhawatirkan, mencerminkan perubahan pola hidup masyarakat yang cenderung kurang aktif secara fisik dan mengonsumsi makanan tinggi kalori.

Dampak ekonomi dari obesitas juga signifikan. Obesitas menyita 8-16% anggaran biaya kesehatan nasional, dan pada tahun 2016, dampak total (langsung dan tidak langsung) dari obesitas diperkirakan sebesar 2-4 miliar dolar AS . Biaya ini mencakup perawatan medis, kehilangan produktivitas, dan beban pada sistem kesehatan secara keseluruhan.

Melihat tren peningkatan prevalensi obesitas dan dampaknya yang luas, diperlukan upaya kolaboratif antara pemerintah, masyarakat, dan sektor swasta untuk mengatasi krisis kesehatan ini secara komprehensif dan berkelanjutan. Intervensi berbasis komunitas, kampanye kesehatan, dan regulasi industri makanan menjadi langkah strategis untuk menekan laju peningkatan obesitas di Indonesia.

# Business Understanding

## Problem Statements

Rumusan masalah dari masalah latar belakang diatas adalah:
1.  Faktor apa saja yang paling berpengaruh terhadap tingkat obesitas seseorang?
2. Bagaimana cara memanfaatkan informasi pola hidup guna memprediksi kategori diabetes pada seseorang?
3. Bagaimana riwayat obesitas dari keluarga memengaruhi level diabetes seseorang?

## GOALS

Berdasarkan problem statements, berikut tujuan yang ingin dicapai pada proyek ini.
1. Mengetahui faktor apa saja yang paling berpengaruh terhadap tingkat obesitas seseorang
2. Mengetahui cara memanfaatkan informasi pola hidup guna memprediksi kategori diabetes pada seseorang
3. Mengetahui hubungan bagaimana riwayat obesitas dari keluarga memengaruhi level diabetes seseorang

## Solution Statements

1.   Melakukan analisis statistik atau membangun model machine learning untuk mengukur seberapa kuat hubungan dan kontribusi tiap faktor terhadap target (tingkat obesitas), sehingga faktor-faktor utama yang paling berpengaruh dapat diidentifikasi.
2.   Menerapkan berbagai algoritma machine learning dan membandingkan hasil performanya untuk menemukan model dengan akurasi terbaik dalam memprediksi tingkat obesitas berdasarkan riwayat kesehatan dan aktivitas seseorang, kemudian menggunakan model terbaik tersebut untuk melakukan prediksi (inference).
3. Melakukan analisis menggunakan variable terkait, untuk memahami kaitan antara riwayat obesitas keluarga dengan tingkat diabetes yang dialami oleh seseorang.

## Metodologi

Tujuan yang ingin dicapai dalam proyek ini adalah memprediksi level diabetes seseorang berdasarkan penelitian yang ada. Metodologi prediktif yang digunakan berfokus pada pembangunan model klasifikasi dengan level diabetes sebagai target utama.

## Metrik

Metrik yang digunakan untuk mengevaluasi seberapa baik model klasifikasi merupakan confusion matrix. confusion matrix merupakan suatu metode yang digunakan untuk melakukan perhitungan akurasi pada konsep data mining.

# Data Understanding

Tahap ini merupakan proses analisis data yang bertujuan untuk memperoleh pemahaman yang menyeluruh mengenai dataset sebelum melanjutkan ke tahap analisis lebih lanjut.

## 1. Mengimport Library

Pada bagian ini kita mengimport seluruh library yang diperlukan untuk menganalisis
"""

!pip install kaggle

pip install optuna

pip install catboost

import os
import shutil
import textwrap
import numpy as np
import zipfile
import math
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import AdaBoostClassifier
import optuna
from catboost import CatBoostClassifier
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder
from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, classification_report

"""## Data Loading

tahap untuk memuat dataset yang akan digunakan agar dataset lebih mudah dipahami.
"""

#!/bin/bash
!curl -L -o obesity-levels.zip\
  "https://www.kaggle.com/api/v1/datasets/download/fatemehmehrparvar/obesity-levels"

#membuka zip menjadi folder
with zipfile.ZipFile("/content/obesity-levels.zip", "r") as zip_ref:
    zip_ref.extractall("obesity-levels")

#membaca csv dalam folder
data = pd.read_csv("/content/obesity-levels/ObesityDataSet_raw_and_data_sinthetic.csv")

# Display the first few rows
data

"""**Insight:**
- Terdapat 17 variabel yang digunakan untuk memprediksi seseorang terkena diabetes.
- Terdapat 2111 data.

### Deskripsi Variabel

| Variabel                          | Keterangan                                                                                         | Contoh Jawaban |
| --------------------------------- | -------------------------------------------------------------------------------------------------- | -------------- |
| Gender                            | Jenis kelamin                                                                                      | Female / Male |
| Age                               | Usia (dalam tahun)                                                                                 | 21.0            |
| Height                            | Tinggi badan (dalam meter)                                                                         | 1.8        |
| Weight                            | Berat badan (dalam kilogram)                                                                       | 68.6        |
| family\_history\_with\_overweight | Apakah ada anggota keluarga yang menderita atau pernah menderita kelebihan berat badan?            | Yes / no        |
| FAVC                              | Apakah sering mengonsumsi makanan berkalori tinggi?                                                | Yes / no        |
| FCVC                              | Apakah biasanya mengonsumsi sayuran dalam makanan?                                                 | Yes / no        |
| NCP                               | Berapa kali makan utama yang dikonsumsi setiap hari?                                               | 1 - 4        |
| CAEC                              | Seberapa sering makan makanan di antara waktu makan utama?                                         | no, sometimes, frequently, always         |
| SMOKE                             | Apakah merokok?                                                                                    | Yes / no        |
| CH2O                              | Berapa banyak air yang diminum setiap hari?                                                        | 1 - 3        |
| SCC                               | Apakah memantau jumlah kalori yang dikonsumsi setiap hari?                                         | Yes / no        |
| FAF                               | Seberapa sering melakukan aktivitas fisik?                                                         | 0 - 3        |
| TUE                               | Seberapa sering menggunakan perangkat teknologi (misal: ponsel, video game, TV, komputer) setiap hari? | 0 - 2        |
| CALC                              | Seberapa sering mengonsumsi alkohol?                                                               | no, sometimes, frequently, always         |
| MTRANS                            | Moda transportasi yang biasa digunakan sehari-hari                                                 | Public_Transportation, Walking, Automobile, Motorbike, Bike         |
| NObeyesdad                        | Tingkat obesitas (target prediksi)                                                                 | Normal_Weight, Overweight_level_I, Overweight_level_II, Obesity_Type_I, Obesity_Type_II, Obesity_Type_III
"""

data.info()

"""**Insight:**
- Terdapat 9 kolom yang bertipe data object, dan 8 kolom bertipe data float64
- Tidak ada data yang missing values.
"""

data.shape

"""Dari Output diatas didapat informasi:
<br>

| Jumlah Baris | Jumlah Kolom |
| ------ | ------ |
| 2111 | 17 |


<br>
"""

# Membuat df
df_filtered = pd.DataFrame(data)

"""### Deskripsi Statistik dari Data"""

# Memanggil untuk statistik data mengecek outlier.
df_filtered.describe()

"""Fungsi `describe()` memberikan informasi statistik pada masing-masing kolom, antara lain:

- `Count` adalah jumlah sampel pada data.
- `Mean` adalah nilai rata-rata.
- `Std` adalah standar deviasi.
- `Min` yaitu nilai minimum setiap kolom.
- `25%` adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- `50%` adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
-` 75%` adalah kuartil ketiga.
- `Max` adalah nilai maksimum.

**Insight:**
1. Umur (Age):

  * Rentang usia dalam dataset ini adalah dari 14 tahun hingga 61 tahun.

  * Rata-rata usia adalah 24,31 tahun, yang mengindikasikan mayoritas data berasal dari usia muda hingga dewasa awal.

  * Standar deviasi (6,34) menunjukkan variasi usia yang cukup beragam.


2. Tinggi Badan (Height):

  * Tinggi badan bervariasi antara 1,45 meter hingga 1,98 meter, dengan rata-rata 1,70 meter.

  * Rentang ini cukup normal, dengan mayoritas data berkumpul di sekitar nilai rata-rata.

3. Berat Badan (Weight):

  * Berat badan dalam dataset berkisar dari 39 kg hingga 173 kg, dengan rata-rata 86,59 kg.

  * Terdapat kemungkinan outlier pada nilai maksimum (173 kg) yang jauh lebih tinggi dari rata-rata.

4. Frekuensi Konsumsi Sayuran (FCVC):

  * FCVC adalah variabel integer yang menunjukkan seberapa sering seseorang mengonsumsi sayuran, dengan nilai rata-rata 2,41 (antara kadang-kadang hingga sering).
  * Minimum 1 dan maksimum 3, sesuai dengan skala yang ditentukan.

5. Jumlah Makan Utama (NCP):

  * Rata-rata jumlah makan utama adalah 2,68 kali per hari.

  * Beberapa orang tampaknya makan lebih sedikit (1 kali) dan ada yang makan hingga 4 kali sehari.

6. Konsumsi Air Harian (CH2O):

  * Rata-rata konsumsi air adalah sekitar 2 liter per hari, dengan minimum 1 liter dan maksimum 4 liter.

  * Pola ini menunjukkan mayoritas orang mengikuti pola konsumsi air yang disarankan.

7. Frekuensi Aktivitas Fisik (FAF):

  * Rata-rata orang dalam dataset ini melakukan aktivitas fisik sekitar 1 kali per minggu.

  * Ada juga individu yang tidak berolahraga sama sekali (0) dan yang melakukannya hingga 3 kali seminggu.

8. Waktu Menggunakan Teknologi (TUE):

  * Rata-rata waktu yang dihabiskan untuk menggunakan perangkat teknologi adalah sekitar 0,65 (antara 0 hingga 2), menunjukkan mayoritas orang menghabiskan waktu sedang dengan perangkat elektronik.

**Temuan Penting:**

* Beberapa fitur seperti Weight dan FAF menunjukkan potensi outlier pada nilai maksimum yang cukup ekstrem dibandingkan nilai rata-ratanya.
* Pola konsumsi sayuran (FCVC) cukup tinggi, namun frekuensi aktivitas fisik (FAF) relatif rendah, yang bisa menjadi faktor risiko obesitas.
* Konsumsi air harian (CH2O) cukup baik di rata-rata, namun variasinya menunjukkan ada yang kurang minum air.

## Exploratory Data Analysis - Univariate Analysis
"""

numerical_feature = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']
categorical_feature = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS', 'NObeyesdad']

"""### Categorical Features"""

# Membentuk plot dengan subplot sejumlah 9 berukuran 4 x 2
fig, axes = plt.subplots(3, 3, figsize=(14, 16))

# Mengubah array multi dimensi menjadi array 1 dimensi
axes = axes.flatten()

# Mendeskripsikan kolom-kolom kategorikal yang akan digunakan
deskripsi_kolom_kategorikal = [
    "Gender (Male/Female)",
    "Family History with Overweight (yes/no)",
    "High Caloric Food Consumption (yes/no)",
    "Food Consumption Between Meals (Sometimes/Frequently/Always)",
    "Smoke (yes/no)",
    "Calorie Monitoring (yes/no)",
    "Alcohol Consumption Frequency (Sometimes/Frequently/Always)",
    "Transportation Mode (Walking/Bike/Public Transportation/etc)",
    "Obesity Levels"
]

# List fitur kategorikal
categorical_feature = [
    'Gender',
    'family_history_with_overweight',
    'FAVC',
    'CAEC',
    'SMOKE',
    'SCC',
    'CALC',
    'MTRANS',
    'NObeyesdad'
]

# Membentuk plot jumlah dalam bentuk bar plot untuk masing-masing kolom
for i, kolom in enumerate(categorical_feature):
    sns.countplot(x=kolom, hue=kolom, data=df_filtered, ax=axes[i], palette='Set2', legend=False)

    # Menambahkan judul untuk masing-masing plot
    judul = "\n".join(textwrap.wrap(f"Plot Jumlah dari {deskripsi_kolom_kategorikal[i]}", width=30))
    axes[i].set_title(judul)
    axes[i].title.set_size(10)

    # Mengatur label x
    axes[i].tick_params(axis="x", labelrotation=45)
    axes[i].tick_params(axis="both", which="major", labelsize=10)
    axes[i].set_xlabel("")

# Mengatur susunan agar tidak berhimpitan
plt.tight_layout()

# Menampilkan plot
plt.show()

"""Gambar di atas dapat diinterpretasikan sebagai berikut.
1. Plot jumlah berdasarkan `Gender` menunjukkan bahwa jumlah responden pria dan wanita relatif seimbang.
2. Plot jumlah berdasarkan `Family History with Overweight` menunjukkan bahwa mayoritas responden memiliki riwayat keluarga yang mengalami kelebihan berat badan.
3. Plot jumlah berdasarkan `High Caloric Food Consumption (FAVC)` menunjukkan bahwa sebagian besar responden sering mengonsumsi makanan tinggi kalori.
4. Plot jumlah berdasarkan `Food Consumption Between Meals (CAEC)` menunjukkan bahwa sebagian besar responden kadang-kadang mengonsumsi camilan di antara waktu makan.
5. Plot jumlah berdasarkan `Smoke` menunjukkan bahwa mayoritas responden tidak merokok.
6. Plot jumlah berdasarkan `Calorie Monitoring (SCC)` menunjukkan bahwa sebagian besar responden tidak memantau jumlah kalori yang mereka konsumsi.
7. Plot jumlah berdasarkan `Alcohol Consumption Frequency (CALC)` menunjukkan bahwa sebagian besar responden kadang-kadang mengonsumsi alkohol, disusul oleh mereka yang tidak mengonsumsinya sama sekali.
8. Plot jumlah berdasarkan `Mode of Transportation (MTRANS)` menunjukkan bahwa mayoritas responden menggunakan transportasi umum dalam kegiatan sehari-hari.
9. Plot jumlah berdasarkan `Obesity Levels (NObeyesdad)` menunjukkan distribusi kelas yang cukup merata, dengan kategori Overweight Level II sebagai yang paling banyak, diikuti oleh Obesity Type III.

### Numerical Features
"""

df_filtered.hist(bins=50, figsize=(20,15), color= 'skyblue')

# Mengatur susunan agar tidak berhimpitan
plt.tight_layout()

#menampilkan plot
plt.show()

"""Gambar di atas dapat diinterpretasikan sebagai berikut.
1. Histogram dari `Height` menunjukkan distribusi yang mendekati normal,
2. Histogram dari `Weight` memiliki distribusi yang lebih bervariasi.
3. Histogram `FCVC` (frekuensi konsumsi sayur) menunjukkan tren kuat pada nilai 2 dan 3, yang berarti sebagian besar responden cukup sering mengonsumsi sayur.
4. Histogram `NCP` (jumlah makan per hari) menunjukkan mayoritas responden makan 3 kali sehari.
5. Histogram dari `CH2O` (konsumsi air) menunjukkan mayoritas responden minum sekitar 2 liter air per hari.
6. Histogram `FAF` (frekuensi aktivitas fisik) menunjukkan bahwa sebagian besar responden memiliki tingkat aktivitas fisik yang rendah, mendekati angka 0.
7. Histogram `TUE` (durasi penggunaan teknologi) juga menunjukkan nilai yang rendah pada sebagian besar responden, yang mengindikasikan bahwa mereka jarang menggunakan perangkat teknologi dalam keseharian.
8. Histogram `Age` memiliki distribusi yang miring ke kanan (right-skewed), yang berarti sebagian besar responden berusia muda, atau berada di bawah rata-rata usia keseluruhan.

## Exploratory Data Analysis - Multivariate Analysis

### Membandingkan kondisi level obesitas dengan riwayat kelebihan berat badan
"""

# Membentuk plot jumlah dalam bentuk bar plot antara kondisi level obesitas dengan riwayat kelebihan berat badan
plt.figure(figsize = (8, 6))
sns.countplot(x = "NObeyesdad", data = df_filtered, hue = "family_history_with_overweight")

# Menambahkan judul pada plot
plt.title("Jumlah Masing-Masing Level Obesitas Berdasarkan Riwayat Kelebihan Berat Badan")

# Menambahkan label sumbu x dan y pada plot
plt.xticks(rotation = 90)
plt.xlabel("Level Obesitas")
plt.ylabel("Jumlah")

# Menampilkan plot
plt.show()

"""**Insight:**
1. Mayoritas penderita obesitas memiliki riwayat keluarga overweight
2. Orang tanpa riwayat keluarga overweight lebih banyak berada di kategori berat badan kurang (Insufficient Weight)

### Membandingkan level obesitas dengan umur
"""

# Membentuk plot strip antara kondisi kesehatan janrunf dengan usia
plt.figure(figsize = (8, 6))
sns.stripplot(data = df_filtered, x = "Age", y = "NObeyesdad")

# Menambahkan judul pada plot
plt.title("Plot Strip kondisi level obesitas dengan Usia")

# Menambahkan label sumbu x dan y pada plot
plt.xlabel("Usia (tahun)")
plt.ylabel("Level Obesitas")

# Menampilkan plot
plt.show()

"""**Insight:**
1. Obesitas bisa terjadi di segala usia, tetapi lebih umum pada usia 20–35 tahun
2. Kategori Obesity_Type_III paling terkonsentrasi di usia sekitar 21–27 tahun
3. Usia muda memiliki variasi status berat badan yang tinggi, mulai dari kekurangan hingga kelebihan berat badan.

### Membandingkan level obesitas dengan pola konsumsi makan
"""

# Atur ukuran plot
plt.figure(figsize=(14, 10))

# Plot 1: FAVC vs NObeyesdad
plt.subplot(2, 2, 1)
sns.countplot(data=df_filtered, x='NObeyesdad', hue='FAVC')
plt.title("FAVC (Konsumsi Makanan Berkalori Tinggi) vs Level Obesitas")
plt.xticks(rotation=45)
plt.xlabel("Level Obesitas")
plt.ylabel("Jumlah Individu")
plt.legend(title='FAVC')

# Plot 2: CAEC vs NObeyesdad
plt.subplot(2, 2, 2)
sns.countplot(data=df_filtered, x='NObeyesdad', hue='CAEC')
plt.title("CAEC (Makan Selain Makan Utama) vs Level Obesitas")
plt.xticks(rotation=45)
plt.xlabel("Level Obesitas")
plt.ylabel("Jumlah Individu")
plt.legend(title='CAEC')

# Plot 3: NCP vs NObeyesdad
plt.subplot(2, 2, 3)
sns.boxplot(data=df_filtered, x='NObeyesdad', y='NCP')
plt.title("NCP (Jumlah Makan Utama per Hari) vs Level Obesitas")
plt.xticks(rotation=45)
plt.xlabel("Level Obesitas")
plt.ylabel("Jumlah Makan Utama per Hari")

# Plot 4: FCVC vs NObeyesdad
plt.subplot(2, 2, 4)
sns.boxplot(data=df_filtered, x='NObeyesdad', y='FCVC')
plt.title("FCVC (Frekuensi Konsumsi Sayur) vs Level Obesitas")
plt.xticks(rotation=45)
plt.xlabel("Level Obesitas")
plt.ylabel("Frekuensi Konsumsi Sayur")

plt.tight_layout()
plt.show()

"""**Insight:**
1. Konsumsi makanan berkalori tinggi (FAVC) berkorelasi positif dengan peningkatan tingkat obesitas.
2. Meskipun kebiasaan ngemil lebih sering ditemukan pada individu obesitas (terutama tipe ringan hingga sedang), namun kategori Insufficient Weight juga menunjukkan frekuensi ngemil yang tinggi, yang menunjukkan bahwa frekuensi ngemil saja tidak cukup menjelaskan obesitas — perlu dilihat juga jenis camilan dan pola konsumsi lainnya.
3. Rata-rata semua kategori obesitas memiliki jumlah makan utama sekitar 3 kali/hari, mirip dengan kategori berat badan normal. Tapi, Insufficient Weight memiliki sebaran nilai lebih tinggi (hingga 4× sehari).
4. Konsumsi sayur tidak signifikan membedakan level obesitas; banyak individu obesitas tetap mengonsumsi sayur.

**Kesimpulan:**
1. Faktor yang paling kuat berhubungan dengan obesitas dari visualisasi ini adalah FAVC (makanan tinggi kalori), diikuti oleh CAEC (ngemil di luar waktu makan utama). Sedangkan jumlah makan utama (NCP) dan konsumsi sayur (FCVC) memiliki pengaruh yang tidak begitu jelas terhadap level obesitas berdasarkan grafik ini.

### Membandingkan kondisi level obesitas dengan kebiasaan merokok dan konsumsi alkohol
"""

# Membuat figure dan dua subplot berdampingan
plt.figure(figsize=(14, 6))  # Ukuran lebar ditambah agar tidak terlalu sempit

# Plot 1: SMOKE vs NObeyesdad
plt.subplot(1, 2, 1)
sns.countplot(data=df_filtered, x='NObeyesdad', hue='SMOKE')
plt.title("Smoke (Merokok) vs Level Obesitas")
plt.xticks(rotation=45)
plt.xlabel("Level Obesitas")
plt.ylabel("Jumlah Individu")
plt.legend(title='Smoke')

# Plot 2: CALC vs NObeyesdad
plt.subplot(1, 2, 2)
sns.countplot(data=df_filtered, x='NObeyesdad', hue='CALC')
plt.title("CALC (Konsumsi Alkohol) vs Level Obesitas")
plt.xticks(rotation=45)
plt.xlabel("Level Obesitas")
plt.ylabel("Jumlah Individu")
plt.legend(title='CALC')

# Menampilkan plot
plt.tight_layout()
plt.show()

"""**Insight:**
1. Level obesitas seseorang tidak ditentukan dengan kebiasaan merokok.
2. Konsumsi alkohol kadang-kadang (Sometimes) paling banyak terjadi pada semua kategori obesitas, termasuk kategori obesitas tertinggi (Obesity_Type_III). Individu yang tidak minum alkohol (CALC = no) mendominasi beberapa kategori awal (seperti Normal_Weight dan Obesity_Type_I), tetapi jumlahnya menurun drastis pada level obesitas paling tinggi.

### Membandingkan kondisi level obesitas dengan Moda transportasi yang biasa digunakan sehari-hari
"""

# Membentuk plot jumlah dalam bentuk bar plot antara kondisi level obesitas dengan riwayat kelebihan berat badan
plt.figure(figsize = (8, 6))
sns.countplot(x = "NObeyesdad", data = df_filtered, hue = "MTRANS")

# Menambahkan judul pada plot
plt.title("Jumlah Masing-Masing Level Obesitas Berdasarkan Riwayat Kelebihan Berat Badan")

# Menambahkan label sumbu x dan y pada plot
plt.xticks(rotation = 90)
plt.xlabel("Level Obesitas")
plt.ylabel("Jumlah")

# Menampilkan plot
plt.show()

"""**Insight:**
1. Transportasi yang tidak aktif secara fisik (seperti public transportation dan mobil pribadi) lebih umum digunakan oleh individu dengan tingkat obesitas lebih tinggi. Sebaliknya, orang yang memilih berjalan kaki atau bersepeda cenderung memiliki berat badan normal atau malah kurang.

### Membandingkan kondisi level obesitas dengan kebiasaan memantau kalori
"""

# Membentuk plot jumlah dalam bentuk bar plot antara kondisi level obesitas dengan riwayat kelebihan berat badan
plt.figure(figsize = (8, 6))
sns.countplot(x = "NObeyesdad", data = df_filtered, hue = "SCC")

# Menambahkan judul pada plot
plt.title("Jumlah Masing-Masing Level Obesitas Berdasarkan Kebiasaan dalam Memantau Kalori")

# Menambahkan label sumbu x dan y pada plot
plt.xticks(rotation = 90)
plt.xlabel("Level Obesitas")
plt.ylabel("Jumlah")

# Menampilkan plot
plt.show()

"""**Insight:**
1. Responden dengan level obesitas tipe 3 tidak ada yang melakukan perhitungan jumlah kalori, sementara pada level lainnya beberapa melakukan hal tersebut.

### Mengetahui distribusi BMI
"""

# Menghitung BMI
df_filtered['BMI'] = df_filtered['Weight'] / (df_filtered['Height'] ** 2)

# Membuat plot BMI
plt.figure(figsize=(10,6))
sns.boxplot(data=df_filtered, x='NObeyesdad', y='BMI')
plt.xticks(rotation=30)
plt.title('Sebaran BMI Berdasarkan Level Obesitas')

# Menampilkan plot
plt.tight_layout()
plt.show()

"""**Insight:**
1. Semakin tinggi level obesitas, semakin tinggi pula nilai median dan sebaran BMI-nya.
2. BMI merupakan indikator yang sangat kuat dan konsisten dalam membedakan level obesitas.

## Data Quality Verification

### Memeriksa Data duplikat
"""

df_filtered.duplicated().sum()

"""**Insight:**
1. Terdapat 24 data duplikat
"""

df_filtered.isnull().sum()

"""**Insight:**

Berdasarkan output sebelumnya, tidak ditemukan nilai missing pada dataset df_filtered. Namun, penting untuk memeriksa keberadaan nilai nol pada setiap kolom, karena pada fitur seperti Gender, Weight, Height, CH2O, dan FCVC, nilai 0 tidak logis secara medis maupun perilaku konsumsi. Selain itu, perlu memeriksa nilai nan atau NaN pada kolom kategorikal. Nilai nol dan nan yang secara tidak sengaja dianggap valid dapat menjadi representasi nilai yang hilang (missing) dan berisiko menurunkan performa model machine learning yang dibangun.
"""

# Menampilkan data duplikat
df_filtered[df_filtered.duplicated]

"""Dari hasil di atas, terlihat bahwa ada data-data tersebut memang terduplikasi. Oleh karena itu, data duplikat ini akan dihapus.

### Memeriksa Data Missing Value

Program di bawah ini digunakan untuk memeriksa apakah ada data umur, tinggi dan berat badan yang bernilai 0.
"""

age = (df_filtered['Age'] == 0).sum()
height = (df_filtered['Height'] == 0).sum()
weight = (df_filtered['Weight'] == 0).sum()

print("Nilai 0 di kolom umur: ", age)
print("Nilai 0 di kolom height: ", height)
print("Nilai 0 di kolom weight: ", weight)

"""Setelah dicek, tidak ada data dari umur, tinggi dan berat badan yang bernilai 0.

Program di bawah ini digunakan untuk memeriksa apakah pada data kategorikal feature terdapat nilai nan
"""

# Cek jumlah NaN asli (np.nan)
print("Jumlah NaN asli:")
print(df_filtered[categorical_feature].isna().sum())
print("================================================")
# Cek nilai kosong string ("") atau spasi (" ")
print("Jumlah string kosong atau spasi:")
print(df_filtered[categorical_feature].isin(["", " "]).sum())
print("================================================")
# Cek nilai string yang umum dipakai sebagai missing
print("Jumlah 'NA' atau 'null' atau 'nan' string:")
print(df_filtered[categorical_feature].isin(["NA", "null", "nan"]).sum())

"""### Memeriksa Data Outlier"""

# Melakukan analisis statistik data setelah dihapus data duplikat dan missing value.
df_filtered.describe()

"""Fungsi `describe()` memberikan informasi statistik pada masing-masing kolom, antara lain:

- `Count` adalah jumlah sampel pada data.
- `Mean` adalah nilai rata-rata.
- `Std` adalah standar deviasi.
- `Min` yaitu nilai minimum setiap kolom.
- `25%` adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- `50%` adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
-` 75%` adalah kuartil ketiga.
- `Max` adalah nilai maksimum.

**Temuan Penting:**
* Terdapat kemungkinan outlier pada nilai maksimum (173 kg) yang jauh lebih tinggi dari rata-rata.
* Beberapa fitur seperti Weight dan FAF menunjukkan potensi outlier pada nilai maksimum yang cukup ekstrem dibandingkan nilai rata-ratanya.
"""

numerical_feature = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']
categorical_feature = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS', 'NObeyesdad']

#Cek data outlier
numerical_features = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']
# Ensure 'data' is the correct DataFrame variable
selected_cols = data[numerical_features] # Changed from df_filtered to data

Q1 = selected_cols.quantile(0.25)
Q3 = selected_cols.quantile(0.75)
IQR = Q3 - Q1

# Correctly filter the DataFrame 'data' and assign to df_cleaned
outlier_condition = ~((selected_cols < (Q1 - 1.5 * IQR)) | (selected_cols > (Q3 + 1.5 * IQR))).any(axis=1)
# Apply the filter to the original 'data' DataFrame
df_cleaned = data[outlier_condition].copy() # Changed from df_filtered to data and added .copy()

# Buat grid 3x3
fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(12, 12))
fig.suptitle('Boxplot of Numerical Features', fontsize=16)

# Flatten axes supaya bisa di-loop
axes = axes.flatten()

# Loop fitur dan plot
for i, feature in enumerate(numerical_feature):
    sns.boxplot(data=df_cleaned, x=feature, ax=axes[i], color='skyblue')
    axes[i].set_title(f'{feature}')
    axes[i].set_xlabel('')

# Sembunyikan subplot yang tidak dipakai (jika jumlah fitur < jumlah grid)
for j in range(len(numerical_feature), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0, 1, 0.96])  # Agar tidak ketimpa judul
plt.show()

"""**Berikut adalah interpretasi dari boxplot di atas.**
1. Pada kolom Age, mayoritas responden berusia antara 20 hingga 25 tahun. Terdapat sejumlah responden dengan usia di atas 35 tahun, namun nilai tersebut masih wajar secara biologis dan tidak akan dihapus dari dataset.
2. Pada kolom `Weight`, dapat dilihat bahwa mayoritas responden memiliki berat badan di rentang 60-100 kilogram. Terdapat satu outlier, yaitu memiliki berat badan 173 kg. Meski demikian, outlier ini tidak akan dihapus karena sangat memungkinkan seseorang obesitas memiliki berat badan ekstrem.
3. Pada kolom `Height`, dapat dilihat bahwa mayoritas responden memiliki tinggi badan di rentang 1,6-1,7 meter. Terdapat satu outlier, yaitu memiliki tinggi badan hampir 2 meter. Meski demikian, outlier ini tidak akan dihapus karena sangat memungkinkan seseorang memiliki tinggi badan tersebut.
4. Pada kolom `NCP`, mayoritas responden makan sebanyak 3 kali sehari. Terdapat variasi jumlah makan dari 1 hingga 4 kali per hari. Nilai-nilai ini masih dianggap wajar karena dapat mencerminkan pola makan individu seperti diet tertentu atau program peningkatan massa otot.
5. Pada kolom `CH2O`,  dapat dilihat bahwa tidak ada outlier. Rata-rata responden minum air sebanyak 1,5-2,5 liter air.
4. Pada kolom-kolom lainnya seperti `FCVC`, `FAF`, dan `TUE`, persebaran data terlihat relatif normal dan tidak menunjukkan nilai ekstrem yang mencolok berdasarkan statistik deskriptif.

**Kesimpulan:**

Dari hasil analisis statistik deskriptif, dapat disimpulkan bahwa beberapa fitur seperti Age, Weight, Height, dan NCP menunjukkan keberadaan nilai yang tergolong ekstrem namun masih valid secara biologis dan kontekstual. Oleh karena itu, nilai-nilai tersebut tidak dihapus dari dataset karena tetap relevan untuk analisis obesitas. Sementara itu, fitur lain seperti CH2O, FAF, dan TUE menunjukkan distribusi data yang relatif normal tanpa adanya nilai yang mencolok sebagai outlier.

# Data Preparation

### Data Cleaning

#### Menangani Data Duplikat
"""

df_cleaned = df_filtered.drop_duplicates()

"""#### Menangani Missing Value"""

# List nilai yang dianggap missing tapi bukan np.nan
missing_vals = ["", " ", "NA", "N/A", "null", "nan", None]

# Ganti nilai tersebut jadi np.nan
df_cleaned[categorical_feature] = df_cleaned[categorical_feature].replace(missing_vals, np.nan)

# Cek kembali jumlah NaN setelah replace
print("Jumlah NaN setelah replace:")
print(df_cleaned[categorical_feature].isna().sum())

df_cleaned = df_cleaned.dropna()

df_cleaned.shape

"""**Insight:**
1. Total data setelah dibersihkan menjadi 2087 baris.

## Encoding Kategorikal

Encoding Kategorikal dilakukan terhadap variabel yang hanya berisi antara `yes` (iya) dan `no` (tidak), yaitu pada variable:
* `FAVC` (Apakah sering mengonsumsi makanan berkalori tinggi?),
* `SCC` (Apakah memantau jumlah kalori yang dikonsumsi setiap hari?),
* `SMOKE` (Apakah merokok?),
* `family_history_with_overweight` (Apakah ada anggota keluarga yang menderita atau pernah menderita kelebihan berat badan?)
"""

df_cleaned['NObeyesdad'].unique()

# Membuat list kolom-kolom kategorikal yang memiliki entri antara yes dan no
Encoding_Kategorikal = ["FAVC", "SCC", "SMOKE","family_history_with_overweight"]

# Mengubah nilai yes menjadi 1 dan nilai no menjadi 0 pada seluruh kolom tersebut
for kategori in Encoding_Kategorikal:
    df_cleaned.loc[:, kategori] = df_cleaned[kategori].map({"yes": 1, "no": 0})

"""## One Hot Encoding

One Hot Encoding dilakukan terhadap 3 variabel, yaitu

* Gender – Male, Female
* CALC – no, Sometimes, Frequently
* CAEC – no, Sometimes, Frequently, dll
* MTRANS – Public_Transportation, Walking, Automobile, Bike, Motorbike (atau lainnya)

karena kategori-kategori pada variabel tersebut memiliki urutan tertentu
"""

# One-hot encoding kolom kategorikal
data_encoded = pd.get_dummies(df_cleaned[["Gender", "CALC", "CAEC", "MTRANS"]], drop_first=True)

# Gabungkan dengan data asli
data = pd.concat([df_cleaned, data_encoded], axis=1)

# Hapus kolom aslinya (yang di-encode)
data.drop(columns=["Gender", "CALC", "CAEC", "MTRANS"], inplace=True)

# Menampilkan lima data teratas yang sudah di encoding dan one hot encoding
data.head()

list(data.columns)

"""## Split train test

Selanjutnya, karena target kita adalah variabel `NObeyesdad` untuk mengetahui akurasi prediksi dari NObeyesdad, maka kita akan membuang kolom tersebut dari data dan assign kolom tersebut ke variabel baru.
"""

from sklearn.model_selection import train_test_split

# Membentuk variabel X sebagai pengaruh dari target
X = data.drop(['NObeyesdad'], axis=1)

# Membentuk variabel y sebagai target
y = data['NObeyesdad']

# Membentuk data training dan data testing dengan komposisi 80% : 20 % dan dirandom setiap dijalankan ulang
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 30)

"""Lalu, kita membagi data menjadi 2, yaitu
* Data training sebesar 80% untuk melatih model
* Data testing sebesar 20% untuk menguji model
"""

# Menampilkan ukuran data training dan testing dari X dan y
print("Ukuran X_train: ", X_train.shape)
print("Ukuran X_test: ", X_test.shape)
print("Ukuran y_train: ", y_train.shape)
print("Ukuran y_test: ", y_test.shape)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## Normalisasi

Algoritma machine learning memiliki performa lebih baik dan konvergen lebih cepat ketika dimodelkan pada data dengan skala relatif sama atau mendekati distribusi normal. Proses scaling dan normalisasi membantu untuk membuat fitur data menjadi bentuk yang lebih mudah diolah oleh algoritma dengan range 0 hingga 1 dan menyeragamkan karena memiliki satuan yang berbeda pada tiap fitur.
"""

# scaling untuk data training
numerical_features= ['Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']
scaler = MinMaxScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

# scaling untuk data testing
numerical_features= ['Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']
scaler = MinMaxScaler()
scaler.fit(X_test[numerical_features])
X_test[numerical_features] = scaler.transform(X_test.loc[:, numerical_features])
X_test[numerical_features].head()

"""# Modeling"""

def make_evaluation(y_true, y_pred, title, target_names=None):
    if target_names is None:
        target_names = ['Normal_Weight', 'Overweight_Level_I', 'Overweight_Level_II',
                        'Obesity_Type_I', 'Insufficient_Weight', 'Obesity_Type_II',
                        'Obesity_Type_III']

    # Gunakan label string sesuai target_names
    labels = target_names

    # Classification report pakai target_names (label string)
    print(classification_report(y_true, y_pred, target_names=target_names))

    # Plot confusion matrix dengan labels string
    fig, ax = plt.subplots(figsize=(10, 5))
    disp = ConfusionMatrixDisplay.from_predictions(y_true, y_pred, ax=ax, labels=labels)

    ax.set_xticklabels(target_names, rotation=90)
    ax.set_yticklabels(target_names)

    ax.grid(False)
    ax.set_title(title)
    plt.tight_layout()
    plt.show()

"""Seluruh model yang akan dibuat menggunakan hyperparameter tuning menggunakan optuna. Optimasi hyperparameter dengan Optuna terbukti efektif dalam meningkatkan performa model untuk mengetahui parameter yang tepat untuk algoritma model pada setiap model [6].

## Model Development dengan Algoritma XGBoost
"""

import pandas as pd
import optuna
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder

# Step 1: Encode target label string ke angka
le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)

# Dapatkan nama kelas dari LabelEncoder
target_nama = le.classes_
num_class = len(target_nama)

# Step 2: Convert fitur ke numpy array jika masih DataFrame
X_train = X_train.values if isinstance(X_train, pd.DataFrame) else X_train
X_test = X_test.values if isinstance(X_test, pd.DataFrame) else X_test

# Fungsi objective untuk Optuna
def objective(trial):
    max_depth = trial.suggest_int('max_depth', 3, 15)
    n_estimators = trial.suggest_int('n_estimators', 50, 200)
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)
    random_state = trial.suggest_int('random_state', 0, 1000)

    model_xgb = XGBClassifier(
        max_depth=max_depth,
        n_estimators=n_estimators,
        learning_rate=learning_rate,
        random_state=random_state,
        n_jobs=-1,
        eval_metric='mlogloss',
        objective='multi:softprob',
        num_class=num_class
    )
    model_xgb.fit(X_train, y_train_encoded)
    y_pred = model_xgb.predict(X_test)
    accuracy = accuracy_score(y_test_encoded, y_pred)
    return accuracy

# Jalankan optimasi Optuna
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)

# Step 9: Tampilkan hasil terbaik hyperparameter dan akurasi tertinggi
print("Best hyperparameters: ", study.best_params)
print("Best accuracy: ", study.best_value)

# Memanggil fungsi XGBClassifier dari library sklearn
model_xgb = XGBClassifier(max_depth = 3, n_estimators = 165,
                          random_state = 9, learning_rate = 0.09828366951253616, n_jobs = -1)

# Melatih model XGBoost dengan data training pada X dan y
model_xgb.fit(X_train, y_train_encoded)

"""Xgboost dengan parameter sebagai berikut:

* max_depth = 3: Menentukan kedalaman maksimal setiap pohon. Jika tidak diatur, pohon akan terus berkembang hingga semua daun menjadi murni atau jumlah sampel di daun kurang dari nilai minimal yang ditentukan.

* learning_rate: 0.09828366951253616 Mengatur seberapa besar pengaruh tiap pohon baru terhadap model akhir. Dengan kata lain, ini mengontrol laju pembelajaran untuk mencegah model menjadi terlalu kompleks (overfitting).

* n_estimators: 165, Jumlah pohon yang dibangun untuk mengurangi kesalahan dari prediksi sebelumnya, meningkatkan akurasi model secara bertahap.

* random_state: 9, Mengatur sumber bilangan acak agar hasil pelatihan bisa konsisten dan dapat diulang.

* n_jobs = -1: Menentukan berapa banyak core CPU yang dipakai saat pelatihan. Jika di-set -1, maka seluruh core yang tersedia akan digunakan supaya proses lebih cepat.
"""

# Prediksi dengan model terbaik
pred_xgb = model_xgb.predict(X_test)

# Ubah encoded prediction dan true label ke label string
y_pred_labels = le.inverse_transform(pred_xgb)
y_test_labels = le.inverse_transform(y_test_encoded)

# Menampilkan akurasi model
xgb = accuracy_score(y_test_encoded, pred_xgb)
accuracy_xgboost= round(accuracy_score(y_test_encoded, pred_xgb)*100,2)
print("hasil akurasi model xgboost: ", accuracy_xgboost,"%")

# Memanggil fungsi make_evaluation untuk menampilkan f1 score dan confusion matrix
make_evaluation(y_test_labels, y_pred_labels, "Confusion Matrix Menggunakan Algoritma XGBoost", target_names=target_nama)

"""Menggunakan XGBoost dimaknai:

1. 59 responden dengan kondisi Insufficient Weight telah diklasifikasikan dengan benar.
2. 38 responden dengan kondisi Normal Weight telah diklasifikasikan dengan benar.
3. 68 responden dengan kondisi Obesity Type I telah diklasifikasikan dengan benar, sementara 4 responden Obesity Type I diklasifikasikan salah sebagai Obesity Type II.
4. 59 responden dengan kondisi Obesity Type II telah diklasifikasikan dengan benar.
5. 80 responden dengan kondisi Obesity Type III telah diklasifikasikan dengan benar.
6. 45 responden dengan kondisi Overweight Level I telah diklasifikasikan dengan benar.
7. 64 responden dengan kondisi Overweight Level II telah diklasifikasikan dengan benar, namun ada 1 responden Overweight Level II yang salah diklasifikasikan sebagai Normal Weight.

## Model Development dengan SVM
"""

# Encode label target string ke angka
le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)

# Dapatkan nama kelas
target_names = le.classes_

# Convert fitur ke numpy array jika masih DataFrame
X_train = X_train.values if isinstance(X_train, pd.DataFrame) else X_train
X_test = X_test.values if isinstance(X_test, pd.DataFrame) else X_test

# Buat model SVM dengan kernel 'rbf' (default)
model_svm = SVC(kernel='rbf', random_state=42)

# Latih model
model_svm.fit(X_train, y_train_encoded)

# Prediksi data test
y_pred_encoded = model_svm.predict(X_test)

# Ubah hasil prediksi encoded ke label string
y_pred_labels = le.inverse_transform(y_pred_encoded)
y_test_labels = le.inverse_transform(y_test_encoded)

"""* Model model_svm = SVC(kernel='rbf', random_state=42) adalah implementasi dari algoritma Support Vector Machine (SVM) untuk klasifikasi, dengan menggunakan kernel RBF (Radial Basis Function).

* Penggunaan kernel='rbf' berarti model akan mencoba menemukan batas pemisah non-linear antara kelas-kelas dalam data. RBF adalah kernel yang umum digunakan karena fleksibel dan mampu menangani data yang tidak dapat dipisahkan secara linear dengan baik, dengan memetakan data ke dalam dimensi yang lebih tinggi.

* Parameter random_state=42 digunakan untuk memastikan bahwa hasil yang diperoleh bersifat konsisten dan bisa direproduksi. Ini penting karena beberapa proses dalam pelatihan SVM (misalnya saat menggunakan algoritma heuristik untuk optimisasi) melibatkan elemen acak. Dengan menentukan nilai random_state, hasil pelatihan akan selalu sama setiap kali model dijalankan.
"""

model_svm.fit(X_train, y_train_encoded)

# Hitung akurasi
accuracy_svm = round(accuracy_score(y_test_encoded, y_pred_encoded)*100,2)
print(f"Akurasi model SVM: {accuracy_svm}%")

# Tampilkan evaluasi
make_evaluation(y_test_labels, y_pred_labels, "Confusion Matrix Menggunakan Algoritma SVM", target_names=target_names)

"""Menggunakan SVM dimaknai:

1. 58 responden dengan kondisi Insufficient Weight telah diklasifikasikan dengan benar, sementara 1 responden salah diklasifikasikan sebagai Normal Weight.
2. 22 responden dengan kondisi Normal Weight telah diklasifikasikan dengan benar, namun:
  * 5 responden salah diklasifikasikan sebagai Insufficient Weight.
  * 11 responden salah diklasifikasikan sebagai Overweight Level I.
3. 65 responden dengan kondisi Obesity Type I telah diklasifikasikan dengan benar, sementara:
  * 4 responden salah diklasifikasikan sebagai Obesity Type II.
  * 3 responden salah diklasifikasikan sebagai Overweight Level II.
4. 59 responden dengan kondisi Obesity Type II telah diklasifikasikan dengan benar.
5. 75 responden dengan kondisi Obesity Type III telah diklasifikasikan dengan benar, sementara 5 responden salah diklasifikasikan sebagai Obesity Type II.
6. 41 responden dengan kondisi Overweight Level I telah diklasifikasikan dengan benar, namun 4 responden salah diklasifikasikan sebagai Overweight Level II.
7. 54 responden dengan kondisi Overweight Level II telah diklasifikasikan dengan benar, namun:
  * 2 responden salah diklasifikasikan sebagai Obesity Type I.
  * 9 responden salah diklasifikasikan sebagai Overweight Level I.

## Model Development dengan Random Forest
"""

# Memanggil fungsi RandomForestClassifier dari library sklearn
model_rf = RandomForestClassifier(n_estimators = 100, criterion = "entropy", max_depth = 10, random_state = 50)

# Melatih model Random Forest dengan data training pada X dan y
model_rf.fit(X_train, y_train)

"""- RandomForestClassifier dengan parameter sebagai berikut:

  - n_estimators=100: artinya akan membangun sebanyak 100 pohon dalam proses pelatihan. Semakin banyak jumlah pohon, biasanya model menjadi lebih akurat dan stabil karena hasil akhir merupakan agregasi dari banyak pohon, namun waktu pelatihan juga akan lebih lama.
  - Parameter criterion="entropy" menunjukkan bahwa pemisahan data di setiap simpul pohon akan didasarkan pada nilai information gain, yang berasal dari teori informasi. Entropy digunakan untuk mengukur ketidakpastian, dan model akan berusaha meminimalkan ketidakpastian ini di setiap split data. Meskipun proses ini sedikit lebih lambat dibandingkan dengan kriteria lain seperti Gini, pemilihan entropy sering kali memberikan hasil prediksi yang lebih baik dalam kasus tertentu.

  - max_depth=10: Menentukan kedalaman maksimum setiap pohon dalam hutan. ini diterapkan untuk mencegah overfitting, yaitu kondisi ketika model terlalu menyesuaikan diri terhadap data pelatihan dan tidak mampu menggeneralisasi dengan baik terhadap data baru. Dengan membatasi kedalaman, model hanya boleh membelah data hingga 10 tingkat saja, sehingga pola yang dipelajari cukup dalam namun tidak terlalu kompleks.

  - random_state=50: digunakan untuk memastikan hasil pelatihan model bisa direproduksi. Dalam konteks pembelajaran mesin, penggunaan random state yang tetap akan menghasilkan hasil yang konsisten setiap kali model dijalankan, karena proses internal seperti pemilihan sampel acak akan menggunakan seed yang sama.

  - n_jobs=-1: Menentukan jumlah inti (cores) yang digunakan untuk menghitung. Jika diatur ke -1, model akan menggunakan semua inti yang tersedia, sehingga mempercepat proses pelatihan.
"""

# Memprediksi hasil menggunakan data testing berdasarkan model yang telat dilatih
pred_rf = model_rf.predict(X_test)

# Menampilkan akurasi model
accuracy_rf= round(accuracy_score(y_test, pred_rf)*100,2)
print("hasil akurasi model Random Forest: ", accuracy_rf,"%")

print(set(type(x) for x in y_test))     # Set tipe data di y_test
print(set(type(x) for x in pred_rf))    # Set tipe data di pred_rf

print(y_test[:10])   # Contoh 10 elemen pertama y_test
print(pred_rf[:10])  # Contoh 10 elemen pertama pred_rf

# Memanggil fungsi make_evaluation untuk menampilkan f1 score dan confusion matrix
make_evaluation(y_test, pred_rf, title="Confusion Matrix Menggunakan Algoritma Random Forest")

"""Menggunakan Random Forest dimaknai:
1. 38 responden dengan kondisi Normal Weight telah diklasifikasikan dengan benar.
2. 42 responden dengan kondisi Overweight Level I telah diklasifikasikan dengan benar, namun 2 responden salah diklasifikasikan sebagai Normal Weight, dan 1 responden sebagai Overweight Level II.
3. 62 responden dengan kondisi Overweight Level II telah diklasifikasikan dengan benar, sementara 1 responden salah diklasifikasikan sebagai Normal Weight, dan 2 responden sebagai Overweight Level I.
4. 71 responden dengan kondisi Obesity Type I telah diklasifikasikan dengan benar, sementara 1 responden salah diklasifikasikan sebagai Insufficient Weight.
5. 58 responden dengan kondisi Insufficient Weight telah diklasifikasikan dengan benar, sementara 1 responden salah diklasifikasikan sebagai Normal Weight.
6. 59 responden dengan kondisi Obesity Type II telah diklasifikasikan dengan benar.
7. 80 responden dengan kondisi Obesity Type III telah diklasifikasikan dengan benar.

# Evaluasi dan Pemilihan Model
"""

# Membentuk DataFrame berisi model dengan akurasinya
models = pd.DataFrame({
    "Model": ["XGBoost", "SVM", "Random Forest"],
    "Akurasi": [accuracy_xgboost, accuracy_svm, accuracy_rf]
})

# Mengurutkan data berdasarkan akurasi dari tertinggi ke terendah
models.sort_values(by = "Akurasi", ascending = False)

"""dari hasil ketiga model algoritma yang dibangun, model terbaik ialah model dengan algoritma XGBoost"""

plt.figure(figsize=(8, 6))

# Buat color palette manual dari colormap viridis sesuai banyaknya model
palette = sns.color_palette("viridis", n_colors=len(models))

barplot = sns.barplot(data=models, x="Model", y="Akurasi", palette=palette)

# Menambahkan label angka di atas bar plot pada masing-masing model
for index, value in enumerate(models["Akurasi"]):
    barplot.text(index, value + 0.02, f"{value:.4f}", color="black", ha="center")

# Menambahkan judul pada plot
plt.title("Perbandingan Akurasi dari ketiga Model")

# Menambahkan label sumbu x dan y pada plot
plt.xlabel("Model")
plt.ylabel("Akurasi")

plt.tight_layout()
plt.show()

"""Berdasarkan gambar di atas dan evaluasi masing-masing model untuk mengetahui skor akurasi, skor F1, dan jumlah kesalahan klasifikasi pada masing-masing model, didapat model *XGBoost* merupakan model terbaik karena memiliki skor akurasi dan skor F1 tertinggi, serta jumlah kesalahan klasifikasi yang paling sedikit, terutama pada cardiovascular."""

# Memanggil fungsi make_evaluation untuk menampilkan f1 score dan confusion matrix
make_evaluation(y_test_labels, y_pred_labels, "Confusion Matrix Menggunakan Algoritma XGBoost", target_names=target_nama)

"""**Interpretasi:**

Menggunakan XGBoost dimaknai:

1. 59 responden dengan kondisi Insufficient Weight telah diklasifikasikan dengan benar.
2. 38 responden dengan kondisi Normal Weight telah diklasifikasikan dengan benar.
3. 68 responden dengan kondisi Obesity Type I telah diklasifikasikan dengan benar, sementara 4 responden Obesity Type I diklasifikasikan salah sebagai Obesity Type II.
4. 59 responden dengan kondisi Obesity Type II telah diklasifikasikan dengan benar.
5. 80 responden dengan kondisi Obesity Type III telah diklasifikasikan dengan benar.
6. 45 responden dengan kondisi Overweight Level I telah diklasifikasikan dengan benar.
7. 64 responden dengan kondisi Overweight Level II telah diklasifikasikan dengan benar, namun ada 1 responden Overweight L

# Menjawab Problems

### 1. Mengetahui faktor apa saja yang paling berpengaruh terhadap tingkat obesitas seseorang

Untuk menjawab permasalahan ini, dilakukan analisis statistik atau membangun model machine learning untuk mengukur seberapa kuat hubungan dan kontribusi tiap faktor terhadap target (tingkat obesitas), sehingga faktor-faktor utama yang paling berpengaruh dapat diidentifikasi, dengan menerapkan program di bawah ini.
"""

#signifikan faktor dari model XGboost (model Terbaik) tersebut yang menggambarkan responden Terkena cardiovascular
feat_importances = pd.Series(model_xgb.feature_importances_,index=X.columns)
feat_importances.nlargest(10).plot(kind='barh')

"""Berdasarkan grafik di atas, 3 faktor yang paling memengaruhi level obesitas seseorang adalah BMI, seorang perempuan, dan sering mengonsumsi makanan tinggi kalori (FAVC)

### 2. Mengetahui cara memanfaatkan informasi pola hidup guna memprediksi kategori diabetes pada seseorang

Untuk menjawab problem tersebut, diperlukan penerapan 3 algoritma machine learning (XGBoost, SVM, dan Random Forest) lalu membandingkan hasil performanya untuk menemukan model dengan akurasi terbaik dalam memprediksi tingkat obesitas berdasarkan riwayat kesehatan dan aktivitas seseorang, kemudian menggunakan model terbaik tersebut untuk melakukan prediksi (inference).
"""

import numpy as np

def infer_obesity_status(model, label_encoder):
    print("Masukkan data berikut untuk prediksi status obesitas Anda:\n")

    # Input numerik
    age = float(input("Umur (tahun): "))
    height = float(input("Tinggi badan (meter): "))
    weight = float(input("Berat badan (kg): "))
    fcvc = float(input("Seberapa sering makan sayur? (1-3): "))
    ncp = float(input("Jumlah makan per hari (1-4): "))
    ch2o = float(input("Jumlah air (liter) per hari (1-3): "))
    faf = float(input("Seberapa sering berolahraga olahraga? (0-3): "))
    tue = float(input("Seberapa sering menggunakan HP/Laptop/Sejenisnya (0-2): "))

    # BMI dihitung otomatis
    bmi = weight / (height ** 2)

    # Input kategorikal → numerik biner
    favc = int(input("Apakah sering makan makanan tinggi kalori? (1=Ya, 0=Tidak): "))
    scc = int(input("Apakah Anda menghitung kalori? (1=Ya, 0=Tidak): "))
    smoke = int(input("Apakah Anda merokok? (1=Ya, 0=Tidak): "))
    family_history = int(input("Ada riwayat keluarga kelebihan berat badan? (1=Ya, 0=Tidak): "))
    gender_input = input("Jenis kelamin? (male/female): ").strip().lower()
    gender_male = 1 if gender_input == 'male' else 0

    # One-hot encoding untuk CALC
    calc_input = input("Konsumsi alkohol (no/sometimes/frequently): ").strip().lower()
    calc_no = int(calc_input == 'no')
    calc_sometimes = int(calc_input == 'sometimes')
    calc_frequently = int(calc_input == 'frequently')

    # One-hot encoding untuk CAEC
    caec_input = input("Ngemil di antara waktu makan? (no/sometimes/frequently): ").strip().lower()
    caec_no = int(caec_input == 'no')
    caec_sometimes = int(caec_input == 'sometimes')
    caec_frequently = int(caec_input == 'frequently')

    # One-hot encoding untuk MTRANS
    mtrans_input = input("Transportasi utama? (walking/bike/motorbike/public): ").strip().lower()
    mtrans_walking = int(mtrans_input == 'walking')
    mtrans_bike = int(mtrans_input == 'bike')
    mtrans_motorbike = int(mtrans_input == 'motorbike')
    mtrans_public = int(mtrans_input == 'public')

    # Susun urutan sesuai model
    fitur_input = np.array([[
        age, height, weight, favc, fcvc, ncp, scc, smoke, ch2o, family_history,
        faf, tue, bmi, gender_male,
        calc_frequently, calc_sometimes, calc_no,
        caec_frequently, caec_sometimes, caec_no,
        mtrans_bike, mtrans_motorbike, mtrans_public, mtrans_walking
    ]])

    # Prediksi
    pred_encoded = model.predict(fitur_input)
    pred_label = label_encoder.inverse_transform(pred_encoded)

    print("\n📊 Prediksi status berat badan Anda adalah:", pred_label[0])

infer_obesity_status(model_xgb, le)

"""> Berdasarkan data yang diinput oleh pengguna berusia 21 tahun dengan tinggi badan 1,5 meter dan berat 68 kg, diketahui bahwa pola makan sehari-harinya kurang seimbang — jarang mengonsumsi sayur (skor 1 dari 3), makan tiga kali sehari, dan mengonsumsi sekitar 2 liter air setiap hari. Aktivitas fisik tergolong rendah dengan olahraga hanya 2 jam per minggu dan waktu layar 1 jam per hari. Pengguna sering mengonsumsi makanan tinggi kalori, tidak menghitung asupan kalori, dan tidak merokok. Terdapat riwayat keluarga mengalami kelebihan berat badan, dan pengguna adalah perempuan. Tidak ada konsumsi alkohol, tidak memiliki kebiasaan ngemil di antara waktu makan, serta menggunakan motor sebagai alat transportasi utama. Berdasarkan informasi tersebut, model memprediksi bahwa individu ini masuk dalam kategori Obesitas Tipe 1.

### 3. Mengetahui hubungan bagaimana riwayat obesitas dari keluarga memengaruhi level diabetes seseorang

Untuk menyelesaikan problems tersebut, maka dilakukan analisis menggunakan variable family_history_with_overweight dan NObesyesdad, untuk memahami kaitan antara riwayat obesitas keluarga dengan tingkat diabetes yang dialami oleh seseorang.
"""

# 1. Cek distribusi obesitas berdasarkan riwayat keluarga
plt.figure(figsize=(10,6))
sns.countplot(data=data, x='NObeyesdad', hue='family_history_with_overweight')
plt.title("Distribusi Level Obesitas Berdasarkan Riwayat Obesitas Keluarga")
plt.xlabel("Level Obesitas")
plt.ylabel("Jumlah")
plt.legend(title="Riwayat Keluarga")
plt.xticks(rotation=30)
plt.tight_layout()
plt.show()

# 2. Hitung proporsi dalam bentuk tabel
prop_table = pd.crosstab(data['NObeyesdad'], data['family_history_with_overweight'], normalize='columns') * 100
print("\nPersentase level obesitas berdasarkan riwayat obesitas keluarga:\n")
print(round(prop_table, 2))

"""> Berdasarkan analisis di atas, dapat dikeathui bahwa individu dengan riwayat obesitas keluarga memiliki kemungkinan jauh lebih besar untuk mengalami obesitas sedang hingga berat dibandingkan individu tanpa riwayat tersebut.

# Referensi

1. Suha, G. R., & Rosyada, A. (2022). Faktor-faktor yang berhubungan dengan kejadian obesitas pada remaja umur 13–15 tahun di Indonesia (analisis lanjut data Riskesdas 2018). Ilmu Gizi Indonesia, 6(1), 43.
2. Batara, A. S. (2018). Healthy Setting Ruang Publik Perkotaan: Sebuah Konsep Terminal Sehat. CV. Social Politic Genius (SIGn).
3. Rahmani, A., & Nadhiroh, S. R. (2024). Upaya yang Dilakukan Beberapa Negara ASEAN untuk Mengatasi Obesitas Anak dan Remaja dalam Program Berbasis Sekolah: Tinjauan Sistematis. Amerta Nutrition, 8(1), 151-160.
4. Pratama, B. A. (2023). Literature Review: Faktor risiko obesitas pada remaja di indonesia. Indonesian Journal on Medical Science, 10(2).
"""